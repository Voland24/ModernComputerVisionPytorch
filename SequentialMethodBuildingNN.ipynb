{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODC60OeQor8HtaXJZ5aYy8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Voland24/ModernComputerVisionPytorch/blob/main/SequentialMethodBuildingNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sequential Method for building a Neural Network**\n",
        "\n",
        "Instead of building our own class for the NN model, we can use the Sequential class and simplify the process"
      ],
      "metadata": {
        "id": "ARGSzP6hFMeW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iqV75OiHEgHP"
      },
      "outputs": [],
      "source": [
        "x = [[1,2],[3,4],[5,6],[7,8]]\n",
        "y = [[3],[7],[11],[15]]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
      ],
      "metadata": {
        "id": "Mb7JXDAgFgbJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "  def __init__(self, x, y):\n",
        "    self.x = torch.tensor(x).float().to(device)\n",
        "    self.y = torch.tensor(y).float().to(device)\n",
        "  def __getitem__(self, index):\n",
        "    return self.x[index], self.y[index]\n",
        "  def __len__(self):\n",
        "    return len(self.x)\n"
      ],
      "metadata": {
        "id": "jCLzt7zPFsow"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = MyDataset(x,y)\n",
        "d1 = DataLoader(ds, batch_size = 2, shuffle = True)\n"
      ],
      "metadata": {
        "id": "gbi_ijetGGD2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now comes the model init"
      ],
      "metadata": {
        "id": "eSVCHqhWGP0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(2,8),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(8,1)\n",
        ").to(device)\n"
      ],
      "metadata": {
        "id": "FbHUU7rGGRSS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing packages neccessary to print the summary of the model"
      ],
      "metadata": {
        "id": "MxcmzZbYGdot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary(model, (1,2)) #name, input_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmiiDOaMGhyV",
        "outputId": "1d5a84fb-5cf0-4638-c563-f002304dd142"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                 [-1, 1, 8]              24\n",
            "              ReLU-2                 [-1, 1, 8]               0\n",
            "            Linear-3                 [-1, 1, 1]               9\n",
            "================================================================\n",
            "Total params: 33\n",
            "Trainable params: 33\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.00\n",
            "Estimated Total Size (MB): 0.00\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = nn.MSELoss()\n",
        "from torch.optim import SGD\n",
        "opt = SGD(model.parameters(), lr = 0.001)\n",
        "import time\n",
        "loss_history = []\n",
        "start = time.time()\n",
        "for _ in range(100):\n",
        "  for ix, iy in d1:\n",
        "    opt.zero_grad()\n",
        "    loss_value = loss_func(model(ix), iy)\n",
        "    loss_value.backward()\n",
        "    opt.step()\n",
        "    loss_history.append(loss_value)\n",
        "end = time.time()\n",
        "print(end - start)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-PXX80dHPqE",
        "outputId": "236cdadf-551c-461e-edf7-d8127d4c872c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0721426010131836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val = [[8,9],[10,11],[1.5,2.5]]\n",
        "\n",
        "model(torch.tensor(val).float().to(device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuJ5VDvgIjTx",
        "outputId": "16bb5fb1-56b2-4550-ccc1-2181f126e3a7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[17.1411],\n",
              "        [21.2419],\n",
              "        [ 3.8138]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Saving and loading a model**\n",
        "\n",
        "We want to save out model after training and load some model so we don't have to train it but we can use it for inference.\n",
        "\n",
        "We save the weights and biases of the model in a dictionary, per layer, so we know how to map it back when laoding it."
      ],
      "metadata": {
        "id": "4Oxf0wlnJN2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.state_dict()\n",
        "\n",
        "#key/value pairs where the keys are the name of the layer and whether we describe the weights or\n",
        "#the biases\n",
        "#and the values are the tensors themselves, values of weights or biases"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xV7QxyqUJfGD",
        "outputId": "9d917e80-e186-45f9-c65d-9c0239167ed7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('0.weight', tensor([[-0.4386, -0.5338],\n",
              "                      [-0.3389, -0.6940],\n",
              "                      [ 0.8834,  0.7201],\n",
              "                      [ 0.8093, -0.2746],\n",
              "                      [ 0.7348, -0.2850],\n",
              "                      [ 0.1053,  0.5454],\n",
              "                      [ 0.6590,  0.1135],\n",
              "                      [-0.2307, -0.1246]])),\n",
              "             ('0.bias',\n",
              "              tensor([-0.4876, -0.3443, -0.2282,  0.2827,  0.5661, -0.5595, -0.2439,  0.0920])),\n",
              "             ('2.weight',\n",
              "              tensor([[ 0.1927, -0.1048,  0.8436,  0.3701,  0.4298,  0.1252,  0.2912,  0.2870]])),\n",
              "             ('2.bias', tensor([0.2391]))])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GOOD PRACTICE**\n",
        "\n",
        "Before saving a model, transfer it from GPU to CPU mem. This will save them as CPU tensors and allow the model to be loaded on a machine that doesn't have PGU capabilities"
      ],
      "metadata": {
        "id": "60Gtlen6J5tH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.to(\"cpu\").state_dict(), 'path/model.pth')"
      ],
      "metadata": {
        "id": "nBg-OOZjKIY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to load the model saved by state_dict()?\n"
      ],
      "metadata": {
        "id": "HAszi-jVKTjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = torch.load('path/model.pth')\n",
        "model.load_state_dict(state_dict)\n",
        "model.to(device) #remember,it was on cpu\n",
        "model(torch.tensor(val).float().to(device)) #use for inference"
      ],
      "metadata": {
        "id": "ypyyCy9SKXC2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}