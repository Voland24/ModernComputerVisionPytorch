{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNB4PJR+9IwE9i7MUOq0kfU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Voland24/ModernComputerVisionPytorch/blob/main/AutoGradsTensorsAndSpeedComparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating gradients of tensors is a useful functionality to have when impementing Neural Networks, since gradients are a core component of gradient descent.\n",
        "When defining a tensor we can specify that we need its gradient to be calculated"
      ],
      "metadata": {
        "id": "0tLqbxhYvTFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x = torch.tensor([[2.,-1,],[1.,1.]], requires_grad = True)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9-G35vqvktY",
        "outputId": "322cdf2f-000b-4ae0-e7a4-e523dbc565be"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 2., -1.],\n",
            "        [ 1.,  1.]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define a simple function for which we want to calculate the gradient i.e. first derivative"
      ],
      "metadata": {
        "id": "SUQQI9S_wCH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out = x.pow(2).sum() # out = sum ( x ** 2)\n",
        "                     #we know the gradient is 2 * x\n",
        "\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAqxZzUqwHd9",
        "outputId": "2f2187f6-ff09-4065-fb58-08723f25c6dc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(7., grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now calculate the gradient in the out function with respect to x i.e. how a small change in x changes the out function\n"
      ],
      "metadata": {
        "id": "vojZqF1Wwdon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out.backward()"
      ],
      "metadata": {
        "id": "-5bPGlLrw2yZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We obtain the gradient of out with respect to x "
      ],
      "metadata": {
        "id": "8aE347alw6SA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grads = x.grad\n",
        "print(grads)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBsEEHQPw-M6",
        "outputId": "22aa1804-f44e-4af2-e583-c5f8b03b7e2e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 4., -2.],\n",
            "        [ 2.,  2.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This matches up with our expectation since we see the gradients are 2 * original value and we analiticaly showed the derivative to be 2 * x"
      ],
      "metadata": {
        "id": "NHd-S9VHxP03"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Why use Pytorch at all?**\n",
        "\n",
        "When updating weights in backprop in a Neural Netowrk, we can see that the updating of one specific weight doesn't impact (and shouldn't) the updates of other weights since they are all updated simultaneously. However, on a CPU they are updated sequentially, i.e we calculate all the drivatives neccessary and then update the weights.\n",
        "\n",
        "We can utilize GPU threads, since they are lightweight and there is a lot of them to update the weights faster. Pytorch is optimized to be run on a GPU."
      ],
      "metadata": {
        "id": "dkAq18wNyKct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(1,6400)\n",
        "y = torch.rand(6400,5000)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu' #run on gpu if available\n",
        "\n",
        "x, y = x.to(device), y.to(device) #transfer the tensors to GPU mem\n",
        "\n",
        "%timeit z = (x@y) #mul two tensors on GPU\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5LYm8osyzHN",
        "outputId": "f99a6af5-74ea-43c6-f28a-89f4df4b9d51"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 6.59 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "25.9 µs ± 27.1 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = x.cpu(), y.cpu()\n",
        "%timeit z = (x@y)\n",
        "\n",
        "#we see how slower it is on a CPU to multiply the same two tensors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stsuaG0E016c",
        "outputId": "dc581436-6c82-4e6f-b373-7ab03c4449da"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9.1 ms ± 83.6 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "x = np.random.random((1,6400))\n",
        "y = np.random.random((6400,5000))\n",
        "%timeit z = np.matmul(x,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvmHE8vH1E2r",
        "outputId": "b3a0b0f9-378a-4cd6-a5f7-735ca438f3b7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19.9 ms ± 544 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPU mul took around 26 microseconds to complete\n",
        "CPU mul of tensors took around 9 milisecs\n",
        "CPU mul of np arrays took around 20milisec"
      ],
      "metadata": {
        "id": "nRO9E_9d1V_I"
      }
    }
  ]
}