{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwCs8cwdqSAwFSFWRySGVA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Voland24/ModernComputerVisionPytorch/blob/main/BuildingANeuralNetPytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "twXydKOE2OFe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "x = [[1,2],[3,4],[5,6],[7,8]] #input values\n",
        "y = [[3],[7],[11],[15]] #output values\n",
        "\n",
        "#trying to teach it addition\n",
        "\n",
        "X = torch.tensor(x).float()\n",
        "Y = torch.tensor(y).float()\n",
        "\n",
        "#Good practice to have tensors as floats or long ints\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "#transfer the tensors to the GPU mem\n",
        "X = X.to(device)\n",
        "Y = Y.to(device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining a class to represent out NN model. We inherit the nn.MOdule class for all the functionalities neccessary.\n",
        "torch.nn offers various helpful functions built-in"
      ],
      "metadata": {
        "id": "lIG5w8HO4RFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyNeuralNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.input_to_hidden_layer = nn.Linear(2,8) #lineal layer w*x + b with 2 inputs and 8 outputs\n",
        "    self.hidden_layer_activation = nn.ReLU()\n",
        "    self.hidden_to_output_layer = nn.Linear(8,1) #same thing 8 ins and 1 out\n",
        "  def forward(self, x):\n",
        "    x = self.input_to_hidden_layer(x)\n",
        "    x = self.hidden_layer_activation(x)\n",
        "    x = self.hidden_to_output_layer(x)\n",
        "    return x\n",
        "    "
      ],
      "metadata": {
        "id": "5fZ5zZrp4cUe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create our model and send it to the GPU memory"
      ],
      "metadata": {
        "id": "hn8nJx1w5EWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.manual_seed(0) #keeps the weights initialized the same random way for each iter in the same runtime\n",
        "mynet = MyNeuralNet().to(device)"
      ],
      "metadata": {
        "id": "SDIg8sQf5J07"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just a sidenote, we can access the weights of the layers like so"
      ],
      "metadata": {
        "id": "LIlou7vz5Rze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(mynet.input_to_hidden_layer.weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff4QhszY5Xxs",
        "outputId": "915bb72b-8612-413d-f094-73bc318e7e88"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.3255, -0.4940],\n",
            "        [-0.6622, -0.4128],\n",
            "        [ 0.6078,  0.3155],\n",
            "        [ 0.3427,  0.0372],\n",
            "        [-0.3625,  0.1196],\n",
            "        [-0.6602, -0.5109],\n",
            "        [-0.3645,  0.4461],\n",
            "        [ 0.4146, -0.3136]], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are predicting a continious output i.e. a regression problem, so we can choose our output function to be the MeanSquaredErrorLoss\n"
      ],
      "metadata": {
        "id": "-Ck-hBxw5_AJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = nn.MSELoss()"
      ],
      "metadata": {
        "id": "CG5cM3Dt6Hk2"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to use and calculate the loss function value?"
      ],
      "metadata": {
        "id": "WmsDoFfY6OWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_Y = mynet(X)\n",
        "loss_value = loss_func(_Y,Y) #torch convention, always send in form (prediction, ground_truth)\n",
        "print(loss_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WizcZQjy6SaO",
        "outputId": "77516291-3f36-48ee-b746-4c6ad3ae2b77"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(112.4196, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just a sidenote, how to see the model parameters"
      ],
      "metadata": {
        "id": "7WNFP33q69vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in mynet.parameters():\n",
        "  print(param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uDEhSWq7BPW",
        "outputId": "516082c7-79ab-4f28-8160-feaa1087e95d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0053,  0.3793],\n",
            "        [-0.5820, -0.5204],\n",
            "        [-0.2723,  0.1896],\n",
            "        [-0.0140,  0.5607],\n",
            "        [-0.0628,  0.1871],\n",
            "        [-0.2137, -0.1390],\n",
            "        [-0.6755, -0.4683],\n",
            "        [-0.2915,  0.0262]], device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.2795,  0.4243, -0.4794, -0.3079,  0.2568,  0.5872, -0.1455,  0.5291],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0570,  0.0374,  0.3201, -0.3280, -0.2226, -0.0895, -0.1378,  0.3055]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.2292], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have the neural net and the loss func, we have to define the optimizer that we will use to reduce the loss error value"
      ],
      "metadata": {
        "id": "k3dAVb8p6lEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import SGD\n",
        "opt = SGD(mynet.parameters(), lr = 0.001)"
      ],
      "metadata": {
        "id": "kZSfaIBj6vAK"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training process is as follows:\n",
        "\n",
        "1.   We flushg the previous epochs grads\n",
        "2.   we compute the loss function on the current params\n",
        "3. we perform the backpass\n",
        "4. we update the params based on their grads\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "psnIrwqg7I4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_history = []\n",
        "for _ in range(50): #number of epochs is 50\n",
        "  opt.zero_grad() #flush the prev grads\n",
        "  loss_value = loss_func(mynet(X), Y) #calc the loss func\n",
        "  loss_value.backward() #the backpass\n",
        "  opt.step() #calculate and update the grads of all the weights and biases\n",
        "  loss_history.append(loss_value)\n",
        "\n",
        "print(type(loss_history))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzckQPGo7Vq8",
        "outputId": "b74321cb-4351-4462-f545-150a31ee7ede"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "val_x = [[10,11]]\n",
        "\n",
        "val_x = torch.tensor(val_x).float().to(device)\n",
        "\n",
        "mynet(val_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ODiEwzzCZk7",
        "outputId": "333185be-4a2f-407d-c2ef-2833baffd07f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[20.5834]], device='cuda:0', grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the loss over epoch graph to see if the model is learning"
      ],
      "metadata": {
        "id": "_TYZ558G7-ak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(torch.tensor(loss_history).detach().numpy())\n",
        "plt.title('Loss func value over epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss func value')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "Q0C8K4Xd8CpS",
        "outputId": "202fe8ab-0f02-44f2-b081-4c40dc5839e8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss func value')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the model is learning and that the loss function is approaching 0 asa the epochs  go on"
      ],
      "metadata": {
        "id": "OjbgLDbX9t0Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Batch size and dataloaders**\n",
        "\n",
        "Batch size is an important part of designing a NN to consider and it's a hyperparameter. It describes just how many datapoint will we use to calculate the gradients i.e the loss value and update the params in a backpass\n",
        "\n",
        "This comes to prominence especially when we consider datasets to have several milion datapoints and running GD on all of them every time we want to calculate the gradients is going to be very slow, although very precise. \n",
        "We will use the batch to retreive a representative sample of the data that is going to be a good enough of a approximation of the whole dataset.\n"
      ],
      "metadata": {
        "id": "Kea8QJMo909C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "  def __init__(self, x, y):\n",
        "    self.x = x.clone().detach().requires_grad_(True)#torch.tensor(x).float()\n",
        "    self.y = y.clone().detach().requires_grad_(True)\n",
        "  def __len__(self):\n",
        "    return len(self.x)\n",
        "  def __getitem__(self, index):\n",
        "    return self.x[index], self.y[index]  #fetching the 'index' row of both datasets"
      ],
      "metadata": {
        "id": "rIzlhwb7_Tey"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = MyDataset(X, Y)"
      ],
      "metadata": {
        "id": "FN2pHtRA__ax"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use the DataLoader class to easily fetch a specifed size or batch of examples from the given dataset"
      ],
      "metadata": {
        "id": "vDuNnEXzAYFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d1 = DataLoader(ds, batch_size = 2, shuffle = True) #shuffle just means that the examples in the batch are randomly chosen\n"
      ],
      "metadata": {
        "id": "86ICsITQAewU"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example of usage"
      ],
      "metadata": {
        "id": "PhWYQZA_ArXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for x, y in d1:\n",
        "  print(x,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpwEzIw1As8N",
        "outputId": "47dc627e-93ae-4ce7-afd9-776301a756e8"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[5., 6.],\n",
            "        [1., 2.]], device='cuda:0', grad_fn=<StackBackward0>) tensor([[11.],\n",
            "        [ 3.]], device='cuda:0', grad_fn=<StackBackward0>)\n",
            "tensor([[7., 8.],\n",
            "        [3., 4.]], device='cuda:0', grad_fn=<StackBackward0>) tensor([[15.],\n",
            "        [ 7.]], device='cuda:0', grad_fn=<StackBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are going to train the NN again, this time using batch GD, meaning we will perform more tham one update per epoch, epoch being looping through the entire dataset once, and we are updating per batch\n",
        "\n",
        "In the example given above, we performed the updates on batch size = 4 i.e the entire dataset per epoch i.e once per epoch.\n",
        "Here the batch size is 2 meaning we have 2X updates per epoch"
      ],
      "metadata": {
        "id": "rHaI3QIvA2Nt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "loss_history = []\n",
        "start = time.time()\n",
        "for _ in range(50):\n",
        "  for data in d1:\n",
        "    x,y = data\n",
        "    opt.zero_grad()\n",
        "    loss_value = loss_func(mynet(x), y)\n",
        "    loss_value.backward()\n",
        "    opt.step()\n",
        "    loss_history.append(loss_value)\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Cew1s7iBCPb",
        "outputId": "5ef2a2c2-c4c2-4a96-937d-c58a340e56c0"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.11580109596252441\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to predict new values?"
      ],
      "metadata": {
        "id": "NDOugIOuCJCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create a test example\n",
        "\n",
        "val_x = [[10,11]]\n",
        "\n",
        "val_x = torch.tensor(val_x).float().to(device)\n",
        "\n",
        "mynet(val_x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mYgm3VECLKw",
        "outputId": "8183d3bd-6815-4f0f-d0aa-e28e6d0f488a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[20.5834]], device='cuda:0', grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Custom loss functions**\n",
        "\n",
        "Somtimes there is a need to define custom loss functions, tailored to our specific problem. This is the case with GANs or object detection problems etc.\n",
        "\n",
        "We will implement and use the MSE loss "
      ],
      "metadata": {
        "id": "vPQwnxXICk37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_mean_squared_error(_y, y):\n",
        "  loss = (_y - y) ** 2\n",
        "  loss = loss.mean()\n",
        "  return loss\n",
        "\n",
        "#sanity scheck\n",
        "\n",
        "print(loss_func(mynet(X), Y))\n",
        "print(my_mean_squared_error(mynet(X), Y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0imgFzosC1s4",
        "outputId": "dff9d932-62db-4d01-fe1b-8720c89cf94d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0433, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "tensor(0.0433, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Looking at hidden layers outputs**\n",
        "\n",
        "This will come in handy in transfer learning, for example looking the output of the CNN layer, the last layer and extracting its feature mapping of the input values i.e image.\n"
      ],
      "metadata": {
        "id": "_2L87HNjDc0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We can call them like functions\n",
        "\n",
        "input_to_hidden = mynet.input_to_hidden_layer(X)\n",
        "hidden_activation = mynet.hidden_layer_activation(input_to_hidden)\n",
        "\n",
        "print(hidden_activation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6ARdeYGDqo0",
        "outputId": "003d92ee-7260-481d-d2aa-1e95889f443c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0000,  0.0000,  2.4913,  1.6628,  0.0000,  0.0000,  0.5450,  0.6073],\n",
            "        [ 0.0000,  0.0000,  5.0791,  3.6700,  0.0000,  0.0000,  1.2647,  1.6914],\n",
            "        [ 0.0000,  0.0000,  7.6668,  5.6772,  0.0000,  0.0000,  1.9844,  2.7755],\n",
            "        [ 0.0000,  0.0000, 10.2546,  7.6845,  0.0000,  0.0000,  2.7041,  3.8595]],\n",
            "       device='cuda:0', grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or we can add in the forward method of the neural net to return not only the last output but however many outputs we want from whatever layers we choose"
      ],
      "metadata": {
        "id": "AKsOz5QFD7Vn"
      }
    }
  ]
}